# app.py
# å­¦ç¿’ãƒãƒ³ãƒ‰ãƒ« models/model.joblib ã‚’èª­ã¿è¾¼ã¿ã€å¯è¦–åŒ–ï¼†æ“ä½œã™ã‚‹UI

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score

st.set_page_config(page_title="Smoker ML Report", layout="wide")
st.title("ğŸš¬ Smoker Classification â€“ å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆ & ãƒ‡ãƒ¢")

# ===== 0) ãƒ¢ãƒ‡ãƒ«/ãƒ¡ã‚¿æƒ…å ±ã®èª­ã¿è¾¼ã¿ =====
obj = joblib.load("models/model.joblib")

# ï¼ˆä¿é™ºï¼‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å˜ä½“ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹å ´åˆã«ã‚‚å‹•ãã‚ˆã†ã«
if isinstance(obj, dict) and "model" in obj:
    bundle = obj
    pipe        = bundle["model"]
    best_name   = bundle.get("best_model_name", "BestModel")
    num_cols    = bundle.get("num_cols", [])
    cat_cols    = bundle.get("cat_cols", [])
    feat_names  = bundle.get("features", num_cols + cat_cols)
    importance  = bundle.get("importance", None)
    coef        = bundle.get("coef", None)
    compare_tbl = pd.DataFrame(bundle.get("compare", {}))
    ev          = bundle.get("eval", {})
    y_true = np.array(ev.get("y_true", []))
    proba  = np.array(ev.get("proba", []))
    fpr    = np.array(ev.get("fpr", []))
    tpr    = np.array(ev.get("tpr", []))
    prec   = np.array(ev.get("prec", []))
    rec    = np.array(ev.get("rec", []))
else:
    # Pipelineã ã‘ä¿å­˜ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼ˆæœ€ä½é™ã®UIï¼‰
    pipe = obj
    best_name = "(pipeline)"
    pre = pipe.named_steps.get("pre", None)
    num_cols, cat_cols = [], []
    if pre is not None and hasattr(pre, "transformers_"):
        for name, trans, cols in pre.transformers_:
            if name == "num": num_cols = list(cols)
            elif name == "cat": cat_cols = list(cols)
    feat_names  = num_cols + cat_cols
    importance  = getattr(pipe.named_steps.get("clf", object()), "feature_importances_", None)
    coef_arr    = getattr(pipe.named_steps.get("clf", object()), "coef_", None)
    coef        = coef_arr[0].tolist() if isinstance(coef_arr, np.ndarray) else None
    compare_tbl = pd.DataFrame([{"model": best_name, "AUC": None, "Accuracy": None, "F1": None}])
    y_true = proba = fpr = tpr = prec = rec = np.array([])

expected = num_cols + cat_cols

# ===== ã‚¿ãƒ–æ§‹æˆ =====
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(
    ["æ¦‚è¦", "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ", "ã—ãã„å€¤ï¼†æ··åŒè¡Œåˆ—", "é‡è¦åº¦/ä¿‚æ•°", "ãƒãƒƒãƒæ´å¯Ÿ", "å€‹åˆ¥äºˆæ¸¬"]
)

with tab1:
    st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ»å‰å‡¦ç†ã®æ¦‚è¦")
    st.markdown(f"""
- ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«: **{best_name}**  
- æ•°å€¤åˆ—: `{num_cols}`  
- ã‚«ãƒ†ã‚´ãƒªåˆ—: `{cat_cols}`  
- å‰å‡¦ç†: æ•°å€¤=æ¬ æä¸­å¤®å€¤â†’æ¨™æº–åŒ–ã€ã‚«ãƒ†ã‚´ãƒª=æ¬ ææœ€é »å€¤â†’OneHot  
""")
    # ROC / PR å¯è¦–åŒ–ï¼ˆæ•°å€¤ã‹ã‚‰æç”»ã§ãã‚‹å ´åˆã®ã¿ï¼‰
    if len(fpr) > 0:
        c1, c2 = st.columns(2)
        with c1:
            fig, ax = plt.subplots()
            ax.plot(fpr, tpr)
            ax.set_xlabel("FPR"); ax.set_ylabel("TPR"); ax.set_title("ROC")
            st.pyplot(fig)
            st.caption(f"AUC (best): {roc_auc_score(y_true, proba):.3f}")
        with c2:
            fig2, ax2 = plt.subplots()
            ax2.plot(rec, prec)
            ax2.set_xlabel("Recall"); ax2.set_ylabel("Precision"); ax2.set_title("PR Curve")
            st.pyplot(fig2)
    else:
        st.info("è©•ä¾¡æ›²ç·šãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã« `python train.py` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

with tab2:
    st.subheader("ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆAUC / Accuracy / F1ï¼‰")
    if not compare_tbl.empty:
        st.dataframe(compare_tbl)
    else:
        st.info("æ¯”è¼ƒè¡¨ãŒã‚ã‚Šã¾ã›ã‚“ã€‚`train.py` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

with tab3:
    st.subheader("ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã«åˆã‚ã›ãŸã—ãã„å€¤ã®èª¿æ•´")
    if len(proba) == 0:
        st.info("è©•ä¾¡ç”¨ã®ç¢ºç‡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚`train.py` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        th = st.slider("åˆ¤å®šã—ãã„å€¤", 0.0, 1.0, 0.5, 0.01)
        y_pred = (proba >= th).astype(int)
        cm = confusion_matrix(y_true, y_pred, labels=[0,1])

        c1, c2, c3 = st.columns(3)
        with c1: st.metric("Precision(1)", f"{precision_score(y_true, y_pred, zero_division=0):.3f}")
        with c2: st.metric("Recall(1)",    f"{recall_score(y_true, y_pred):.3f}")
        with c3: st.metric("F1",           f"{f1_score(y_true, y_pred):.3f}")

        st.markdown("**Confusion Matrix (labels=[0,1])**")
        st.dataframe(pd.DataFrame(cm, index=["True 0","True 1"], columns=["Pred 0","Pred 1"]))

with tab4:
    st.subheader("ã©ã®ç‰¹å¾´ãŒåŠ¹ã„ãŸã‹ï¼ˆå¯„ä¸ã®å¯è¦–åŒ–ï¼‰")
    if importance is not None:
        df_imp = pd.DataFrame({"feature": feat_names, "importance": importance}).sort_values("importance", ascending=False)
        st.bar_chart(df_imp.set_index("feature").head(10))
        st.caption("â€» ãƒ„ãƒªãƒ¼ç³»ã®é‡è¦åº¦ï¼šèª¤å·®æ¸›å°‘å¯„ä¸ã®åˆè¨ˆ")
    elif coef is not None:
        df_coef = pd.DataFrame({"feature": feat_names, "coef": coef})
        df_coef["abs"] = df_coef["coef"].abs()
        df_coef = df_coef.sort_values("abs", ascending=False).drop(columns="abs")
        st.bar_chart(df_coef.set_index("feature").head(10))
        st.caption("â€» ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®ä¿‚æ•°ï¼šç¬¦å·=æ–¹å‘ã€çµ¶å¯¾å€¤=å¯„ä¸å¼·åº¦")
    else:
        st.info("ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ç°¡æ˜“é‡è¦åº¦ã‚’æä¾›ã—ã¾ã›ã‚“ã€‚")

with tab5:
    st.subheader("CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§å‚¾å‘ã‚’å¯è¦–åŒ–")
    f = st.file_uploader("å­¦ç¿’æ™‚ã®åˆ—ã‚’å«ã‚€ CSV ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv"])
    if f is not None:
        df_u = pd.read_csv(f)
        Xb = df_u.reindex(columns=expected)
        prob_b = pipe.predict_proba(Xb)[:, 1]
        pred_b = (prob_b >= 0.5).astype(int)

        st.write("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df_u.head())

        # å–«ç…™ç¢ºç‡ã®åˆ†å¸ƒ
        st.markdown("**å–«ç…™ç¢ºç‡ã®åˆ†å¸ƒ**")
        fig, ax = plt.subplots()
        ax.hist(prob_b, bins=20, range=(0, 1))
        ax.set_xlabel("Probability")
        ax.set_ylabel("Count")
        st.pyplot(fig)

        # TOPç‰¹å¾´ï¼ˆç¾ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«åŸºæº–ï¼‰
        st.markdown("**ç‰¹å¾´ã®å¯„ä¸ï¼ˆTOP10ï¼‰**")
        clf = pipe.named_steps["clf"]
        if hasattr(clf, "feature_importances_"):
            imp_df = pd.DataFrame({"feature": feat_names, "importance": clf.feature_importances_}).sort_values("importance", ascending=False)
            st.bar_chart(imp_df.set_index("feature").head(10))
        elif hasattr(clf, "coef_"):
            cf = clf.coef_[0]
            cdf = pd.DataFrame({"feature": feat_names, "coef": cf})
            cdf["abs"] = cdf["coef"].abs()
            st.bar_chart(cdf.sort_values("abs", ascending=False).set_index("feature").head(10)[["coef"]])

with tab6:
    st.subheader("å€‹åˆ¥äºˆæ¸¬ï¼ˆå®Ÿé‹ç”¨ã®é›°å›²æ°—ï¼‰")
    with st.sidebar:
        st.markdown("### å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆ1äººåˆ†ï¼‰")
        user = {}
        for c in num_cols:
            user[c] = st.number_input(c, value=0.0, step=1.0, format="%.2f")
        for c in cat_cols:
            user[c] = st.text_input(c, value="")
    xin = pd.DataFrame([user]).reindex(columns=expected)
    p = float(pipe.predict_proba(xin)[0, 1])
    st.metric("å–«ç…™è€…ç¢ºç‡", f"{p*100:.1f}%")
    st.write("åˆ¤å®š:", "å–«ç…™è€…" if p >= 0.5 else "éå–«ç…™è€…")